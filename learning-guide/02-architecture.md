# 🏗️ SGLang 架构设计

> **目标**：读完本文，你将理解 SGLang 的多进程架构、核心组件的职责，以及它们如何协作。

---

## 1. 全局架构图

```
                    ┌─────────────────────────────────────────────┐
                    │              主进程 (Main Process)            │
                    │                                              │
  用户请求 ──────▶  │  ┌──────────────┐    ┌───────────────────┐  │
  (HTTP)            │  │  HTTP Server │    │ TokenizerManager  │  │
                    │  │  (FastAPI)   │───▶│   (分词管理器)      │  │
                    │  └──────────────┘    └────────┬──────────┘  │
                    │                               │ ZMQ          │
                    │  ┌───────────────────┐        │              │
  返回结果 ◀──────  │  │DetokenizerManager │◀───────┼──────┐      │
                    │  │  (反分词管理器)     │        │      │      │
                    │  └───────────────────┘        │      │      │
                    └───────────────────────────────┼──────┼──────┘
                                                    │      │
                                          ZMQ 消息  │      │ ZMQ 消息
                                            (请求)  │      │ (结果)
                                                    ▼      │
                    ┌───────────────────────────────────────┼──────┐
                    │           调度进程 (Scheduler Process) │      │
                    │                                       │      │
                    │  ┌─────────────┐                      │      │
                    │  │  Scheduler  │──────────────────────┘      │
                    │  │  (调度器)    │                              │
                    │  └──────┬──────┘                              │
                    │         │                                     │
                    │         ▼                                     │
                    │  ┌─────────────┐    ┌─────────────┐          │
                    │  │  TpWorker   │    │ ModelRunner  │          │
                    │  │ (并行工作器) │───▶│ (模型运行器)  │          │
                    │  └─────────────┘    └──────┬──────┘          │
                    │                            │                 │
                    │                     ┌──────▼──────┐          │
                    │                     │    GPU 🔥    │          │
                    │                     │  (显卡计算)   │          │
                    │                     └─────────────┘          │
                    └──────────────────────────────────────────────┘
```

**比喻理解**：这就像一家大型餐厅的组织架构

| 组件 | 餐厅角色 | 职责 |
|------|---------|------|
| HTTP Server | 前台接待 | 接收顾客（请求），记录需求 |
| TokenizerManager | 点单员 | 把顾客的话翻译成厨房能懂的"菜单"（Token） |
| Scheduler | 餐厅经理 | 决定哪些菜先做、分配给哪个厨师 |
| TpWorker | 厨师长 | 协调多个厨师（GPU）一起做大菜 |
| ModelRunner | 厨师 | 实际动手做菜（GPU 计算） |
| DetokenizerManager | 传菜员 | 把做好的菜（Token）送到顾客手上（转为文字） |

---

## 2. 为什么要用多进程？

你可能会问：为什么不把所有代码放在一个程序里？

**原因 1：分工提效**
- 分词和 GPU 计算的速度差异极大
- 如果放在一起，快的要等慢的，大家都慢下来
- 分开后，各干各的，互不影响

**原因 2：GPU 专注计算**
- GPU 最怕被打断（上下文切换很昂贵）
- 把 GPU 相关的操作放在独立进程中，可以让 GPU 持续满载工作
- 其他工作（分词、网络通信）在 CPU 上独立运行

**原因 3：可扩展性**
- 多 GPU 时，每个 GPU 一个工作进程
- 主进程不需要知道有多少 GPU，只和调度器通信

> 💡 **比喻**：就像餐厅里前厅和后厨分开——服务员不需要进厨房，厨师不需要出来接待客人，各司其职效率最高。

---

## 3. 三大核心组件详解

### 3.1 TokenizerManager（分词管理器）

**位置**：主进程中
**文件**：`python/sglang/srt/managers/tokenizer_manager.py`

**职责**：
1. 接收用户的文本输入
2. 把文本转换为 Token ID 序列（分词）
3. 通过 ZMQ 把 Token 发送给 Scheduler
4. 等待结果并返回给用户

```
"请介绍一下Python" → TokenizerManager → [8345, 2190, 567, 1234, 8901]
```

### 3.2 Scheduler（调度器）

**位置**：独立进程（或与 GPU 工作进程在同一进程）
**文件**：`python/sglang/srt/managers/scheduler.py`

**职责**：
1. 从 ZMQ 接收新请求
2. 维护等待队列和运行队列
3. 决定当前这一步要处理哪些请求（组成一个"批次"）
4. 把批次交给 TpWorker/ModelRunner 执行
5. 把结果通过 ZMQ 发回给 TokenizerManager/DetokenizerManager

**核心决策**：
- 先做 Prefill 还是 Decode？
- 这个批次最多放多少请求？
- 内存不够时，哪些请求暂时"搁置"？

### 3.3 ModelRunner（模型运行器）

**位置**：GPU 工作进程内
**文件**：`python/sglang/srt/model_executor/model_runner.py`

**职责**：
1. 加载模型权重到 GPU 显存
2. 执行前向传播（Forward Pass）——核心计算
3. 管理 KV Cache
4. 使用 CUDA Graph 优化重复计算

---

## 4. 进程间通信：ZMQ

### 什么是 ZMQ？

ZMQ（ZeroMQ）是一个轻量级的消息传递库。你可以把它想象成进程之间的"对讲机"。

```
TokenizerManager ──── ZMQ 消息 ────▶ Scheduler
                                          │
                                    ZMQ 消息（结果）
                                          │
DetokenizerManager ◀──────────────────────┘
```

### 为什么用 ZMQ 而不是其他方式？

| 通信方式 | 优点 | 缺点 | SGLang 选择 |
|---------|------|------|------------|
| 共享内存 | 极快 | 编程复杂 | 用于大数据（Token 数组） |
| ZMQ | 简单可靠、支持多模式 | 有序列化开销 | ✅ 主要通信方式 |
| HTTP | 标准通用 | 太重量级 | 仅用于外部 API |
| gRPC | 高效 | 配置复杂 | 未使用 |

---

## 5. 数据流概览

一个请求在系统中的完整流动：

```
步骤 1: 用户发送 HTTP 请求
        POST /v1/chat/completions
        {"messages": [{"role": "user", "content": "你好"}]}
            │
            ▼
步骤 2: HTTP Server 接收请求，调用 TokenizerManager
            │
            ▼
步骤 3: TokenizerManager 分词
        "你好" → [12345, 67890]
            │
            ▼
步骤 4: 通过 ZMQ 发送到 Scheduler
        消息内容：GenerateReqInput(token_ids=[12345, 67890], ...)
            │
            ▼
步骤 5: Scheduler 将请求加入等待队列
            │
            ▼
步骤 6: Scheduler 组成批次，交给 ModelRunner
            │
            ▼
步骤 7: ModelRunner 在 GPU 上执行前向传播
        输入 [12345, 67890] → 输出 [23456]（下一个 Token）
            │
            ▼
步骤 8: 重复步骤 6-7，直到生成完成
            │
            ▼
步骤 9: Scheduler 通过 ZMQ 发送结果给 DetokenizerManager
            │
            ▼
步骤 10: DetokenizerManager 反分词，返回给用户
         [23456, 34567, ...] → "你好！有什么可以帮助你的？"
```

---

## 6. 下一步

- 想了解服务器如何启动 → [服务器启动](03-server-startup.md)
- 想跟踪一个请求的详细旅程 → [推理请求的旅程](04-request-journey.md)
- 返回目录 → [README](README.md)
