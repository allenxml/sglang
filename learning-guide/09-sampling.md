# 🎲 采样与生成

> **目标**：理解模型生成文字时如何从候选词中"选词"，以及 Temperature、Top-P、Top-K 的含义。

---

## 1. 模型输出的不是文字，而是概率

模型的前向传播输出的是一个巨大的概率分布——**词表中每个词被选为"下一个词"的概率**：

```
输入: "今天天气真"

模型输出（logits → 概率）:
  "好"   → 35%
  "不"   → 20%
  "的"   → 8%
  "棒"   → 7%
  "热"   → 5%
  "冷"   → 4%
  ...
  (词表中所有 128000 个词都有一个概率)
```

**采样**（Sampling）就是从这个概率分布中选出一个词的过程。

> 💡 **比喻**：想象一个巨大的转盘，每个词占的面积和它的概率成正比。"好"占 35% 的面积，"不"占 20%。转一次转盘，指针指到哪个词就选哪个。

---

## 2. 贪心 vs 采样

### 贪心解码（Greedy Decoding）

最简单的策略：**每次选概率最高的词**。

```
"今天天气真" → "好"(35%) → "，"(40%) → "适合"(25%) → "出去"(30%) → ...
```

**优点**：结果确定、稳定
**缺点**：输出单调、重复，缺乏创造力

### 随机采样（Random Sampling）

按概率**随机抽取**一个词。

```
第一次运行: "今天天气真" → "好"(被抽中)
第二次运行: "今天天气真" → "棒"(被抽中)
第三次运行: "今天天气真" → "不"(被抽中)
```

**优点**：输出多样、有创造力
**缺点**：可能选到不合理的词

---

## 3. Temperature（温度）

Temperature 控制概率分布的"平坦程度"：

### Temperature = 0（等同贪心）

```
"好" → 99%  ████████████████████
"不" → 1%   █
"棒" → 0%
"热" → 0%
→ 几乎一定选"好"
```

### Temperature = 0.7（常用值）

```
"好" → 45%  █████████
"不" → 25%  █████
"棒" → 15%  ███
"热" → 10%  ██
"冷" → 5%   █
→ 大概率选"好"，但也可能选其他词
```

### Temperature = 1.5（高温度）

```
"好" → 22%  ████
"不" → 18%  ████
"棒" → 16%  ███
"热" → 15%  ███
"冷" → 14%  ███
"差" → 15%  ███
→ 各个词被选中的概率差不多，非常随机
```

> 💡 **比喻**：
> - **低温度** = 严格的考试评分，只有标准答案才得满分
> - **高温度** = 头脑风暴，各种想法都值得尝试
> - **温度为 0** = 照本宣科，每次说一模一样的话

---

## 4. Top-K 采样

**Top-K**：只从概率最高的 K 个词中选择，忽略其余的。

```
K = 3 时：

原始分布:               过滤后（只保留 Top-3）:
"好" → 35%              "好" → 50%  (重新归一化)
"不" → 20%      →       "不" → 29%
"棒" → 15%              "棒" → 21%
"热" → 5%               (被排除)
"冷" → 4%               (被排除)
...                     (被排除)
```

**效果**：防止选到概率很低的"离谱"词。

> 💡 **比喻**：点菜时只看菜单前 3 名推荐菜，不考虑其他的。

---

## 5. Top-P 采样（Nucleus Sampling）

**Top-P**：从累计概率达到 P 的最小词集中选择。

```
P = 0.8 时：

按概率排序:
"好" → 35%  (累计: 35%)   ✓ 保留
"不" → 20%  (累计: 55%)   ✓ 保留
"棒" → 15%  (累计: 70%)   ✓ 保留
"热" → 8%   (累计: 78%)   ✓ 保留
"冷" → 5%   (累计: 83%)   ✓ 保留（超过 80%，到此为止）
"差" → 4%   (累计: 87%)   ✗ 排除
...                       ✗ 排除
```

**效果**：比 Top-K 更灵活——
- 当模型很确定时（一个词概率 90%），只保留 1-2 个候选
- 当模型不确定时（多个词概率接近），保留更多候选

> 💡 **比喻**：点菜时说"给我推荐几道菜，总分加起来超过 80 分的那几道就行"。如果有一道 90 分的，就只推荐那一道；如果最高只有 30 分，就推荐好几道。

---

## 6. 采样参数的组合使用

实际使用中，这些参数通常组合使用：

```
步骤 1: 模型输出 logits
    ↓
步骤 2: 应用 Temperature（调整概率分布）
    ↓
步骤 3: 应用 Top-K（只保留前 K 个）
    ↓
步骤 4: 应用 Top-P（只保留累计概率达 P 的）
    ↓
步骤 5: 从剩余候选中按概率采样
    ↓
结果: 一个 Token ID
```

### 常用参数组合

| 场景 | Temperature | Top-P | Top-K | 效果 |
|------|------------|-------|-------|------|
| 代码生成 | 0 | - | - | 确定性输出，避免语法错误 |
| 日常对话 | 0.7 | 0.9 | - | 自然流畅，偶尔有创意 |
| 创意写作 | 1.0 | 0.95 | - | 丰富多样，富有想象力 |
| 头脑风暴 | 1.2 | 0.95 | 50 | 非常发散，可能出奇制胜 |

---

## 7. 其他采样相关参数

### Repetition Penalty（重复惩罚）

降低已经出现过的词的概率，避免模型"卡壳"式重复：

```
没有重复惩罚:
"我喜欢吃苹果，我喜欢吃苹果，我喜欢吃苹果..."  😩

有重复惩罚:
"我喜欢吃苹果，也爱吃香蕉，偶尔还会吃葡萄。"  😊
```

### Max Tokens（最大生成长度）

限制生成的 Token 数量，防止无限生成：

```
max_tokens = 100  → 最多生成 100 个 Token 后强制停止
```

### Stop Sequences（停止序列）

遇到指定的文字就停止生成：

```
stop = ["\n\n", "。"]  → 遇到双换行或句号就停止
```

---

## 8. 采样在代码中的位置

```
Scheduler
  └── ModelRunner.forward_decode()
       └── 模型前向传播 → logits
            └── Sampler（采样器）
                 ├── apply_temperature()
                 ├── apply_top_k()
                 ├── apply_top_p()
                 └── sample() → Token ID
```

采样器接收模型输出的 logits，经过一系列处理后，为批次中的每个请求选出下一个 Token。

---

## 9. 下一步

- 查阅完整术语表 → [术语表](10-glossary.md)
- 返回请求流程全貌 → [推理请求的旅程](04-request-journey.md)
- 返回目录 → [README](README.md)
