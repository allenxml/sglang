# ================================================================================
# ðŸ“Š è¯·æ±‚æŒ‡æ ‡å¯¼å‡ºå™¨ (Request Metrics Exporter)
# ================================================================================
#
# ã€è¿™ä¸ªæ–‡ä»¶æ˜¯ä»€ä¹ˆã€‘What This File Does
# è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†è¯·æ±‚çº§åˆ«æ€§èƒ½æŒ‡æ ‡çš„å¯¼å‡ºç³»ç»Ÿï¼Œç”¨äºŽå°†æ¯ä¸ªè¯·æ±‚çš„æ€§èƒ½æ•°æ®ï¼ˆå»¶è¿Ÿã€åžåé‡ç­‰ï¼‰
# æŒä¹…åŒ–åˆ°å¤–éƒ¨å­˜å‚¨ï¼ˆæ–‡ä»¶ã€æ•°æ®åº“ã€Prometheusç­‰ï¼‰ï¼Œä¸ºç”Ÿäº§çŽ¯å¢ƒç›‘æŽ§å’Œåˆ†æžæä¾›æ•°æ®åŸºç¡€ã€‚
#
# ã€ç”Ÿæ´»æ¯”å–»ã€‘Metaphor
# æƒ³è±¡è¿™æ˜¯ä¸€ä¸ª"ä½“æ£€æŠ¥å‘Šæ‰“å°ä¸­å¿ƒ"ï¼š
# - æ¯ä¸ªè¯·æ±‚ = ä¸€ä½ç—…äºº
# - æ€§èƒ½æŒ‡æ ‡ = ä½“æ£€é¡¹ç›®ç»“æžœï¼ˆå¿ƒçŽ‡ã€è¡€åŽ‹ã€è¡€ç³–ç­‰ï¼‰
# - RequestMetricsExporter = æ‰“å°æœºï¼ˆå¯ä»¥æ‰“å°åˆ°çº¸ä¸Šã€å­˜åˆ°æ•°æ®åº“ã€å‘é€é‚®ä»¶ï¼‰
# - RequestMetricsExporterManager = æ‰“å°ä¸­å¿ƒï¼ˆç®¡ç†å¤šå°æ‰“å°æœºåŒæ—¶å·¥ä½œï¼‰
#
# ã€æ ¸å¿ƒæž¶æž„ã€‘Architecture
# 1. RequestMetricsExporterï¼ˆæŠ½è±¡åŸºç±»ï¼‰
#    â”œâ”€ å®šä¹‰ç»Ÿä¸€çš„å¯¼å‡ºæŽ¥å£
#    â””â”€ æä¾›é€šç”¨çš„æ•°æ®æ ¼å¼åŒ–æ–¹æ³•
#
# 2. FileRequestMetricsExporterï¼ˆæ–‡ä»¶å¯¼å‡ºå®žçŽ°ï¼‰
#    â”œâ”€ å°†æŒ‡æ ‡å†™å…¥æœ¬åœ°æ—¥å¿—æ–‡ä»¶
#    â”œâ”€ æŒ‰å°æ—¶æ»šåŠ¨æ—¥å¿—ï¼ˆé¿å…å•æ–‡ä»¶è¿‡å¤§ï¼‰
#    â””â”€ JSON Lines æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
#
# 3. RequestMetricsExporterManagerï¼ˆå¯¼å‡ºå™¨ç®¡ç†å™¨ï¼‰
#    â”œâ”€ æ”¯æŒåŒæ—¶å¯ç”¨å¤šä¸ªå¯¼å‡ºå™¨
#    â”œâ”€ ç»Ÿä¸€è°ƒåº¦å†™å…¥æ“ä½œ
#    â””â”€ æ”¯æŒç§æœ‰æ’ä»¶æ‰©å±•
#
# ã€å…¸åž‹æŒ‡æ ‡ã€‘Typical Metrics
# - å»¶è¿Ÿç±»ï¼še2e_latency_ms, prefill_latency_ms, decode_latency_ms
# - åžåé‡ï¼šinput_tokens, output_tokens, throughput_tps
# - èµ„æºï¼šqueue_wait_ms, batch_size, gpu_memory_used
#
# ã€ä½¿ç”¨æ–¹å¼ã€‘Usage
# å¯åŠ¨æœåŠ¡æ—¶æ·»åŠ  --export-metrics-to-file å‚æ•°ï¼š
#   python -m sglang.launch_server \
#     --export-metrics-to-file \
#     --export-metrics-to-file-dir ./logs/metrics
#
# ================================================================================

import asyncio
import dataclasses
import json
import logging
import os
from abc import ABC, abstractmethod
from datetime import datetime
from typing import List, Optional, Union

from sglang.srt.managers.io_struct import EmbeddingReqInput, GenerateReqInput  # è¯·æ±‚è¾“å…¥æ•°æ®ç»“æž„
from sglang.srt.server_args import ServerArgs  # æœåŠ¡å™¨å¯åŠ¨å‚æ•°

logger = logging.getLogger(__name__)

# ======== éœ€è¦æŽ’é™¤çš„å­—æ®µï¼ˆä¸å¯JSONåºåˆ—åŒ–ï¼‰========
# Fields that should always be excluded from request parameters
# because they contain non-JSON-serializable objects (e.g., ImageData, tensors)
#
# è¿™äº›å­—æ®µåŒ…å«äºŒè¿›åˆ¶æ•°æ®ï¼ˆå›¾åƒã€è§†é¢‘ã€å¼ é‡ï¼‰ï¼Œæ— æ³•ç›´æŽ¥è½¬ä¸º JSON
ALWAYS_EXCLUDE_FIELDS = {"image_data", "video_data", "audio_data", "input_embeds"}


# ======== æŠ½è±¡åŸºç±»ï¼šRequestMetricsExporter ========
class RequestMetricsExporter(ABC):
    """Abstract base class for exporting request-level performance metrics to a data destination."""

    def __init__(
        self,
        server_args: ServerArgs,
        obj_skip_names: Optional[set[str]],
        out_skip_names: Optional[set[str]],
    ):
        self.server_args = server_args
        self.obj_skip_names = obj_skip_names or set()
        self.out_skip_names = out_skip_names or set()

    def _format_output_data(
        self, obj: Union[GenerateReqInput, EmbeddingReqInput], out_dict: dict
    ) -> dict:
        """Format request-level output data containing performance metrics. This method
        should be called prior to writing the data record with `self.write_record()`."""

        request_params = {}
        for field in dataclasses.fields(obj):
            field_name = field.name
            # Skip fields in obj_skip_names or fields that are always excluded (not JSON serializable)
            if (
                field_name not in self.obj_skip_names
                and field_name not in ALWAYS_EXCLUDE_FIELDS
            ):
                value = getattr(obj, field_name)
                # Convert to serializable format
                if value is not None:
                    request_params[field_name] = value

        meta_info = out_dict.get("meta_info", {})
        filtered_out_meta_info = {
            k: v for k, v in meta_info.items() if k not in self.out_skip_names
        }

        request_output_data = {
            "request_parameters": json.dumps(request_params),
            **filtered_out_meta_info,
        }
        return request_output_data

    @abstractmethod
    async def write_record(
        self, obj: Union[GenerateReqInput, EmbeddingReqInput], out_dict: dict
    ):
        """Write a data record corresponding to a single request, containing performance metric data."""
        pass


# ======== æ–‡ä»¶å¯¼å‡ºå®žçŽ°ï¼šFileRequestMetricsExporter ========
class FileRequestMetricsExporter(RequestMetricsExporter):
    """
    æ–‡ä»¶å¯¼å‡ºå™¨ï¼šå°†è¯·æ±‚æŒ‡æ ‡å†™å…¥æœ¬åœ°æ—¥å¿—æ–‡ä»¶ (JSON Lines æ ¼å¼)

    Lightweight `RequestMetricsExporter` implementation that writes records to files on disk.

    Records are written to files in the directory specified by `--export-metrics-to-file-dir`
    server launch flag. File names are of the form `"sglang-request-metrics-{hour_suffix}.log"`.

    ã€æ ¸å¿ƒç‰¹æ€§ã€‘
    - æŒ‰å°æ—¶æ»šåŠ¨ï¼šæ¯å°æ—¶åˆ›å»ºæ–°æ–‡ä»¶ï¼ˆå¦‚ sglang-request-metrics-20260211_14.logï¼‰
    - JSON Lines æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ˜“äºŽæµå¼è§£æž
    - å¼‚æ­¥å†™å…¥ï¼šé¿å…é˜»å¡žä¸»çº¿ç¨‹

    ã€æ–‡ä»¶æ ¼å¼ç¤ºä¾‹ã€‘
    {"request_parameters": {...}, "e2e_latency_ms": 1234, "input_tokens": 50, ...}
    {"request_parameters": {...}, "e2e_latency_ms": 2345, "input_tokens": 120, ...}
    """

    def __init__(
        self,
        server_args: ServerArgs,
        obj_skip_names: Optional[set[str]],
        out_skip_names: Optional[set[str]],
    ):
        super().__init__(server_args, obj_skip_names, out_skip_names)
        self.export_dir = getattr(server_args, "export_metrics_to_file_dir")
        os.makedirs(self.export_dir, exist_ok=True)  # åˆ›å»ºç›®å½•ï¼ˆå¦‚æžœä¸å­˜åœ¨ï¼‰

        # ======== æ–‡ä»¶å¥æŸ„çŠ¶æ€ç®¡ç† ========
        # File handler state management
        self._current_file_handler = None  # å½“å‰æ‰“å¼€çš„æ–‡ä»¶å¥æŸ„
        self._current_hour_suffix = None  # å½“å‰å°æ—¶åŽç¼€ï¼ˆå¦‚ "20260211_14"ï¼‰

    def _ensure_file_handler(self, hour_suffix: str):
        """
        ç¡®ä¿å½“å‰å°æ—¶å¯¹åº”çš„æ–‡ä»¶å¥æŸ„å·²æ‰“å¼€ï¼ˆæŒ‰å°æ—¶æ»šåŠ¨æ—¥å¿—ï¼‰

        Ensure the file handler is open for the current hour suffix.

        ã€å·¥ä½œåŽŸç†ã€‘
        - å¦‚æžœå½“å‰å°æ—¶ä¸Žä¸Šæ¬¡ä¸åŒ â†’ å…³é—­æ—§æ–‡ä»¶ï¼Œæ‰“å¼€æ–°æ–‡ä»¶
        - å¦‚æžœå½“å‰å°æ—¶ä¸Žä¸Šæ¬¡ç›¸åŒ â†’ å¤ç”¨å·²æ‰“å¼€çš„æ–‡ä»¶å¥æŸ„
        """
        if self._current_hour_suffix != hour_suffix:
            # ======== å…³é—­æ—§çš„æ–‡ä»¶å¥æŸ„ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰========
            # Close previous file handler if it exists
            if self._current_file_handler is not None:
                try:
                    self._current_file_handler.close()
                except Exception as e:
                    logger.warning(f"Failed to close previous file handler: {e}")

            # Open new file handler
            log_filename = f"sglang-request-metrics-{hour_suffix}.log"
            log_filepath = os.path.join(self.export_dir, log_filename)

            try:
                self._current_file_handler = open(log_filepath, "a", encoding="utf-8")
                self._current_hour_suffix = hour_suffix
            except Exception as e:
                logger.error(f"Failed to open log file {log_filepath}: {e}")
                self._current_file_handler = None
                self._current_hour_suffix = None
                raise

    def close(self):
        """Close the current file handler."""
        if self._current_file_handler is not None:
            try:
                self._current_file_handler.close()
            except Exception as e:
                logger.warning(f"Failed to close file handler: {e}")
            finally:
                self._current_file_handler = None
                self._current_hour_suffix = None

    async def write_record(
        self, obj: Union[GenerateReqInput, EmbeddingReqInput], out_dict: dict
    ):
        """
        å°†å•ä¸ªè¯·æ±‚çš„æŒ‡æ ‡æ•°æ®å†™å…¥æ–‡ä»¶ï¼ˆå¼‚æ­¥ï¼Œé¿å…é˜»å¡žï¼‰

        ã€å·¥ä½œæµç¨‹ã€‘
        1. è¿‡æ»¤å¥åº·æ£€æŸ¥è¯·æ±‚ï¼ˆä¸è®°å½•ï¼‰
        2. èŽ·å–å½“å‰å°æ—¶åŽç¼€ï¼ˆå¦‚ "20260211_14"ï¼‰
        3. ç¡®ä¿å¯¹åº”å°æ—¶çš„æ–‡ä»¶å·²æ‰“å¼€
        4. æ ¼å¼åŒ–æŒ‡æ ‡æ•°æ®ä¸º JSON
        5. å¼‚æ­¥å†™å…¥æ–‡ä»¶ï¼ˆä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡žä¸»çº¿ç¨‹ï¼‰
        """
        # ======== ç¬¬1æ­¥ï¼šè¿‡æ»¤å¥åº·æ£€æŸ¥è¯·æ±‚ ========
        # Do not log health check requests, since they don't represent real user requests.
        if isinstance(obj.rid, str) and "HEALTH_CHECK" in obj.rid:
            return

        try:
            # ======== ç¬¬2æ­¥ï¼šèŽ·å–å½“å‰å°æ—¶åŽç¼€ ========
            # Get the log file path for the current time.
            current_time = datetime.now()
            hour_suffix = current_time.strftime("%Y%m%d_%H")  # æ ¼å¼ï¼š20260211_14

            # ======== ç¬¬3æ­¥ï¼šç¡®ä¿å¯¹åº”æ–‡ä»¶å·²æ‰“å¼€ ========
            # Ensure correct file handler is open for current hour
            self._ensure_file_handler(hour_suffix)

            if self._current_file_handler is None:
                return  # æ–‡ä»¶æ‰“å¼€å¤±è´¥ï¼Œè·³è¿‡

            # ======== ç¬¬4æ­¥ï¼šæ ¼å¼åŒ–æŒ‡æ ‡æ•°æ® ========
            metrics_data = self._format_output_data(obj, out_dict)

            # ======== ç¬¬5æ­¥ï¼šå¼‚æ­¥å†™å…¥æ–‡ä»¶ ========
            # ä½¿ç”¨ asyncio.to_thread åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œé˜»å¡žçš„æ–‡ä»¶å†™å…¥æ“ä½œ
            def write_file():
                json.dump(metrics_data, self._current_file_handler)  # å†™å…¥JSONå¯¹è±¡
                self._current_file_handler.write("\n")  # æ¢è¡Œï¼ˆJSON Lines æ ¼å¼ï¼‰
                self._current_file_handler.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜

            await asyncio.to_thread(write_file)
        except Exception as e:
            logger.exception(f"Failed to write perf metrics to file: {e}")


# ======== å¯¼å‡ºå™¨ç®¡ç†å™¨ï¼šRequestMetricsExporterManager ========
class RequestMetricsExporterManager:
    """
    æŒ‡æ ‡å¯¼å‡ºå™¨ç®¡ç†å™¨ï¼šæ”¯æŒåŒæ—¶å¯ç”¨å¤šä¸ªå¯¼å‡ºç›®æ ‡

    Manager class for creating and managing RequestMetricsExporter instances.

    ã€æ ¸å¿ƒåŠŸèƒ½ã€‘
    - æ ¹æ®å¯åŠ¨å‚æ•°è‡ªåŠ¨åˆ›å»ºå¯¼å‡ºå™¨ï¼ˆæ–‡ä»¶ã€æ•°æ®åº“ã€Prometheusç­‰ï¼‰
    - æ”¯æŒåŒæ—¶å¯¼å‡ºåˆ°å¤šä¸ªç›®æ ‡ï¼ˆå¦‚åŒæ—¶å†™æ–‡ä»¶å’ŒæŽ¨é€åˆ°ç›‘æŽ§ç³»ç»Ÿï¼‰
    - ç»Ÿä¸€è°ƒåº¦æ‰€æœ‰å¯¼å‡ºå™¨çš„å†™å…¥æ“ä½œ
    - æ”¯æŒç§æœ‰æ’ä»¶æ‰©å±•ï¼ˆé€šè¿‡ sglang.private åŒ…ï¼‰

    ã€ä½¿ç”¨ç¤ºä¾‹ã€‘
    manager = RequestMetricsExporterManager(server_args)
    if manager.exporter_enabled():
        await manager.write_record(req_input, output_dict)
    """

    def __init__(
        self,
        server_args: ServerArgs,
        obj_skip_names: Optional[set[str]] = None,
        out_skip_names: Optional[set[str]] = None,
    ):
        self.server_args = server_args
        self.obj_skip_names = obj_skip_names or set()  # è¾“å…¥å¯¹è±¡ä¸­éœ€è¦è·³è¿‡çš„å­—æ®µ
        self.out_skip_names = out_skip_names or set()  # è¾“å‡ºå­—å…¸ä¸­éœ€è¦è·³è¿‡çš„å­—æ®µ
        self._exporters: List[RequestMetricsExporter] = []  # å·²å¯ç”¨çš„å¯¼å‡ºå™¨åˆ—è¡¨
        self._create_exporters()  # æ ¹æ®é…ç½®åˆ›å»ºå¯¼å‡ºå™¨

    def _create_exporters(self) -> None:
        """Create and configure RequestMetricsExporter instances based on server args."""
        # Create standard exporters
        self._exporters.extend(
            create_request_metrics_exporters(
                self.server_args, self.obj_skip_names, self.out_skip_names
            )
        )

        # Import additional RequestMetricsExporter from private fork if available; skip otherwise.
        try:
            from sglang.private.managers.request_metrics_exporter_factory import (
                create_private_request_metrics_exporters,
            )

            self._exporters.extend(
                create_private_request_metrics_exporters(
                    self.server_args, self.obj_skip_names, self.out_skip_names
                )
            )
        except ImportError:
            pass

    def exporter_enabled(self) -> bool:
        """Return true if at least one RequestMetricsExporter is enabled."""
        return len(self._exporters) > 0

    async def write_record(self, obj, out_dict: dict) -> None:
        """Write a record using all configured exporters."""
        for exporter in self._exporters:
            await exporter.write_record(obj, out_dict)


def create_request_metrics_exporters(
    server_args: ServerArgs,
    obj_skip_names: Optional[set[str]] = None,
    out_skip_names: Optional[set[str]] = None,
) -> List[RequestMetricsExporter]:
    """Create and configure `RequestMetricsExporter`s based on server args."""
    metrics_exporters = []

    if server_args.export_metrics_to_file:
        metrics_exporters.append(
            FileRequestMetricsExporter(server_args, obj_skip_names, out_skip_names)
        )

    return metrics_exporters
